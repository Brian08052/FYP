{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.wired.com/2011/01/linear-regression-with-pylab/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def getFileName(dataID):\n",
    "  return 'Dic' + str(dataID)\n",
    "\n",
    "def createPickleWithDic(dataID, d):\n",
    "    fileName = getFileName(dataID)\n",
    "    file = open(fileName, 'wb+')\n",
    "    pickle.dump(d, file)\n",
    "    file.close()\n",
    "    return\n",
    "    \n",
    "def createPickle(dataID):\n",
    "  d = createDictionary(dataID)\n",
    "  fileName = getFileName(dataID)\n",
    "  file = open(fileName, 'wb+')\n",
    "  pickle.dump(d, file)\n",
    "  file.close()\n",
    "  return\n",
    "\n",
    "def updatePickle(dataID):\n",
    "    #not sure if this overwrites it, or if you need to clear it first\n",
    "    createPickle(dataID)\n",
    "\n",
    "    \n",
    "def getDicFromPickle(dataID):\n",
    "  fileName = getFileName(dataID)\n",
    "  file2 = open(fileName, 'rb')\n",
    "  new_d = pickle.load(file2)\n",
    "  file2.close()\n",
    "  return new_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic2 = getDicFromPickle('cleanData')\n",
    "import math\n",
    "\n",
    "dataX = []\n",
    "dataY = []\n",
    "logdataY = []\n",
    "\n",
    "for key in dic2:\n",
    "    for i in range(len(dic2[key])):\n",
    "        dataX += [i]\n",
    "        dataY += [dic2[key][i]]\n",
    "        if dic2[key][i] == 0:\n",
    "            logdataY += [0]\n",
    "        else:\n",
    "            logdataY += [math.log(dic2[key][i])]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from collections import Counter\n",
    "import numpy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    " \n",
    "stop_words = (stop_words.ENGLISH_STOP_WORDS)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import add_dummy_feature\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Class, for use in pipelines, to select certain columns from a DataFrame and convert to a numpy array\n",
    "# From A. Geron: Hands-On Machine Learning with Scikit-Learn & TensorFlow, O'Reilly, 2017\n",
    "# Modified by Derek Bridge to allow for casting in the same ways as pandas.DatFrame.astype\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names, dtype=None):\n",
    "        self.attribute_names = attribute_names\n",
    "        self.dtype = dtype\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_selected = X[self.attribute_names]\n",
    "        if self.dtype:\n",
    "            return X_selected.astype(self.dtype).values\n",
    "        return X_selected.values\n",
    "    \n",
    "# Class, for use in pipelines, to binarize nominal-valued features (while avoiding the dummy variabe trap)\n",
    "# By Derek Bridge, 2017\n",
    "class FeatureBinarizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features_values):\n",
    "        self.features_values = features_values\n",
    "        self.num_features = len(features_values)\n",
    "        self.labelencodings = [LabelEncoder().fit(feature_values) for feature_values in features_values]\n",
    "        self.onehotencoder = OneHotEncoder(sparse=False,\n",
    "            n_values=[len(feature_values) for feature_values in features_values])\n",
    "        self.last_indexes = np.cumsum([len(feature_values) - 1 for feature_values in self.features_values])\n",
    "    def fit(self, X, y=None):\n",
    "        for i in range(0, self.num_features):\n",
    "            X[:, i] = self.labelencodings[i].transform(X[:, i])\n",
    "        return self.onehotencoder.fit(X)\n",
    "    def transform(self, X, y=None):\n",
    "        for i in range(0, self.num_features):\n",
    "            X[:, i] = self.labelencodings[i].transform(X[:, i])\n",
    "        onehotencoded = self.onehotencoder.transform(X)\n",
    "        return np.delete(onehotencoded, self.last_indexes, axis=1)\n",
    "    def fit_transform(self, X, y=None):\n",
    "        onehotencoded = self.fit(X).transform(X)\n",
    "        return np.delete(onehotencoded, self.last_indexes, axis=1)\n",
    "    def get_params(self, deep=True):\n",
    "        return {\"features_values\" : self.features_values}\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            self.setattr(parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(i):\n",
    "    return 2*i+7\n",
    "\n",
    "x = [1,5,3,6,3,2,6,7,4,2,7,8,3]\n",
    "y = []\n",
    "\n",
    "for i in x:\n",
    "    y+= [f(i)]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'col1': [x], 'col2' : [y]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 5, 3, 6, 3, 2, 6, 7, 4, 2, 7, 8, 3]</td>\n",
       "      <td>[9, 17, 13, 19, 13, 11, 19, 21, 15, 11, 21, 23...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      col1  \\\n",
       "0  [1, 5, 3, 6, 3, 2, 6, 7, 4, 2, 7, 8, 3]   \n",
       "\n",
       "                                                col2  \n",
       "0  [9, 17, 13, 19, 13, 11, 19, 21, 15, 11, 21, 23...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 17, 13, 19, 13, 11, 19, 21, 15, 11, 21, 23, 13]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col1    object\n",
       "col2    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = pd.Series(x)\n",
    "ys = pd.Series(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'x1' : xs, 'y1' : ys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1  y1\n",
       "0    1   9\n",
       "1    5  17\n",
       "2    3  13\n",
       "3    6  19\n",
       "4    3  13\n",
       "5    2  11\n",
       "6    6  19\n",
       "7    7  21\n",
       "8    4  15\n",
       "9    2  11\n",
       "10   7  21\n",
       "11   8  23\n",
       "12   3  13"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>tot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  y1  tot\n",
       "0   1   9   10\n",
       "1   5  17   22\n",
       "2   3  13   16\n",
       "3   6  19   25\n",
       "4   3  13   16"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.assign(tot = d['x1'] + d['y1']).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (df.assign(tot = d['x1'] + d['y1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "#X = df.drop('tot', axis = 1)\n",
    "#y= df['tot']\n",
    "y= df['y1']\n",
    "X = df.drop('y1', axis = 1)\n",
    "\n",
    "\n",
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'copy_X': True, 'fit_intercept': True, 'n_jobs': 1, 'normalize': False}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x9eabc70>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8e677f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df.x1, df.y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.,  17.,  13.,  19.,  13.,  11.,  19.,  21.,  15.,  11.,  21.,\n",
       "        23.,  13.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x9f33870>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOgAk4v8Aacl74LG4PzEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8e9fd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df.y1, lm.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanSquaredError = np.mean((df.y1 - lm.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7328566760003855e-16"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1,1) and (2,) not aligned: 1 (dim 1) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-420a5744e3a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\brian\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \"\"\"\n\u001b[1;32m--> 256\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\brian\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[1;32m--> 241\u001b[1;33m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\brian\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (1,1) and (2,) not aligned: 1 (dim 1) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "lm.predict(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.fit_intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(m,b) = polyfit(dataX,logdataY,1)\n",
    "print(m,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\brian\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n 25 26 27 28 29 30 31 32 33 34 35].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-a45fb2a5774a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mlm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxPred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;31m#meanSquaredError = np.mean((df.y1 - lm.predict(X)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\brian\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \"\"\"\n\u001b[1;32m--> 256\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\brian\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"coef_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m    241\u001b[0m                                dense_output=True) + self.intercept_\n",
      "\u001b[1;32mc:\\users\\brian\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    408\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    411\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m             \u001b[1;31m# To ensure that array flags are maintained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n 25 26 27 28 29 30 31 32 33 34 35].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUn2kbxtPRwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb6a63d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = dataX\n",
    "y = logdataY\n",
    "\n",
    "xs = pd.Series(x)\n",
    "ys = pd.Series(y)\n",
    "d = {'x1' : xs, 'y1' : ys}\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "y= df['y1']\n",
    "X = df.drop('y1', axis = 1)\n",
    "\n",
    "xPred = []\n",
    "for i in range(36):\n",
    "    xPred += [i]\n",
    "\n",
    "xPred = pd.Series(xPred)\n",
    "xPred.reshape(-1, 1)\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X, y)\n",
    "lm.get_params()\n",
    "plt.scatter(df.x1, df.y1)\n",
    "lm.predict(X)\n",
    "plt.scatter(df.y1, lm.predict(xPred))\n",
    "#meanSquaredError = np.mean((df.y1 - lm.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.198413355505 5.00275002369\n"
     ]
    }
   ],
   "source": [
    "(m, b) = polyfit(x,y,1)\n",
    "print(m, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ployval' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-fdd334d9290d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0myp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mployval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ployval' is not defined"
     ]
    }
   ],
   "source": [
    "yp = ployval([m,b], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [171471,\n",
       "  87250.0,\n",
       "  3029,\n",
       "  3323.0,\n",
       "  3617,\n",
       "  5654,\n",
       "  5090,\n",
       "  4369,\n",
       "  2679,\n",
       "  885,\n",
       "  249,\n",
       "  30,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 3: [439986,\n",
       "  11597,\n",
       "  3664,\n",
       "  1250,\n",
       "  357,\n",
       "  154,\n",
       "  72,\n",
       "  26,\n",
       "  13,\n",
       "  7,\n",
       "  4,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 4: [111581,\n",
       "  2400,\n",
       "  469,\n",
       "  236,\n",
       "  290,\n",
       "  88,\n",
       "  34,\n",
       "  11,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 5: [178594,\n",
       "  1783,\n",
       "  248,\n",
       "  56,\n",
       "  17,\n",
       "  8,\n",
       "  4,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 6: [488811,\n",
       "  11959,\n",
       "  1525,\n",
       "  713,\n",
       "  424,\n",
       "  499,\n",
       "  728,\n",
       "  404.5,\n",
       "  81,\n",
       "  88,\n",
       "  25,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 7: [69,\n",
       "  24,\n",
       "  8,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 8: [19,\n",
       "  12,\n",
       "  7,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 9: [5407,\n",
       "  2729.5,\n",
       "  52,\n",
       "  12,\n",
       "  4,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 10: [274392,\n",
       "  3010,\n",
       "  579,\n",
       "  163,\n",
       "  63,\n",
       "  33,\n",
       "  17,\n",
       "  11,\n",
       "  6,\n",
       "  4,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 11: [242245,\n",
       "  3414,\n",
       "  614,\n",
       "  295,\n",
       "  213,\n",
       "  160.0,\n",
       "  107,\n",
       "  75,\n",
       "  63,\n",
       "  31,\n",
       "  17,\n",
       "  14,\n",
       "  8,\n",
       "  4,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 12: [565701,\n",
       "  342265,\n",
       "  16360,\n",
       "  1979,\n",
       "  504,\n",
       "  182,\n",
       "  82,\n",
       "  59,\n",
       "  36,\n",
       "  12,\n",
       "  8,\n",
       "  5,\n",
       "  4.0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 13: [36450,\n",
       "  58223.5,\n",
       "  79997,\n",
       "  20798,\n",
       "  1943,\n",
       "  252,\n",
       "  58,\n",
       "  19,\n",
       "  8,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 15: [151911,\n",
       "  48969,\n",
       "  16261,\n",
       "  8324.5,\n",
       "  388,\n",
       "  113,\n",
       "  38,\n",
       "  30.0,\n",
       "  22,\n",
       "  25.5,\n",
       "  29,\n",
       "  33,\n",
       "  45,\n",
       "  29.0,\n",
       "  13,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 16: [19991,\n",
       "  5551,\n",
       "  3709,\n",
       "  3568,\n",
       "  722,\n",
       "  110,\n",
       "  48,\n",
       "  36.0,\n",
       "  24,\n",
       "  18,\n",
       "  15,\n",
       "  8,\n",
       "  5,\n",
       "  5.0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 17: [20727,\n",
       "  19468,\n",
       "  17695.0,\n",
       "  15922,\n",
       "  676,\n",
       "  145,\n",
       "  39,\n",
       "  18,\n",
       "  8,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 18: [121768,\n",
       "  218972,\n",
       "  8754,\n",
       "  3980,\n",
       "  3327,\n",
       "  1729,\n",
       "  1159,\n",
       "  612,\n",
       "  366,\n",
       "  197,\n",
       "  7,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 19: [108018,\n",
       "  6104,\n",
       "  2792,\n",
       "  394,\n",
       "  30,\n",
       "  12,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 20: [40428,\n",
       "  32460,\n",
       "  4612,\n",
       "  2106,\n",
       "  821,\n",
       "  652,\n",
       "  507,\n",
       "  436,\n",
       "  473,\n",
       "  408,\n",
       "  227,\n",
       "  201,\n",
       "  184,\n",
       "  196,\n",
       "  109.5,\n",
       "  23,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 21: [96884,\n",
       "  4041,\n",
       "  1644,\n",
       "  620,\n",
       "  6,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 22: [29455,\n",
       "  2376,\n",
       "  112,\n",
       "  34,\n",
       "  26,\n",
       "  11,\n",
       "  9,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 23: [7189,\n",
       "  15822,\n",
       "  18300.0,\n",
       "  20778,\n",
       "  9412,\n",
       "  969,\n",
       "  62,\n",
       "  32.5,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 24: [14365,\n",
       "  7308.0,\n",
       "  251,\n",
       "  152.0,\n",
       "  53,\n",
       "  27.5,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 25: [73320,\n",
       "  1336,\n",
       "  145,\n",
       "  43,\n",
       "  18,\n",
       "  6,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 26: [166859,\n",
       "  176230,\n",
       "  37749,\n",
       "  1425,\n",
       "  223,\n",
       "  65,\n",
       "  28,\n",
       "  11,\n",
       "  6,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 27: [17876,\n",
       "  8975.0,\n",
       "  74,\n",
       "  44.0,\n",
       "  14,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 28: [631112,\n",
       "  18516,\n",
       "  4243,\n",
       "  1026,\n",
       "  313,\n",
       "  199,\n",
       "  204,\n",
       "  209,\n",
       "  153,\n",
       "  38,\n",
       "  20.0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 29: [11964,\n",
       "  450,\n",
       "  49,\n",
       "  10,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 30: [773545,\n",
       "  6607,\n",
       "  1104,\n",
       "  264,\n",
       "  99,\n",
       "  55,\n",
       "  50,\n",
       "  45,\n",
       "  41,\n",
       "  8,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 31: [3438,\n",
       "  2555,\n",
       "  1672,\n",
       "  790,\n",
       "  557.5,\n",
       "  325,\n",
       "  166.5,\n",
       "  8,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 32: [358977,\n",
       "  407433,\n",
       "  76489,\n",
       "  2796,\n",
       "  644,\n",
       "  192,\n",
       "  87,\n",
       "  49,\n",
       "  27,\n",
       "  16,\n",
       "  9,\n",
       "  6,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'data': [], 'type': []})\n",
    "rows = []\n",
    "for message in questions:\n",
    "    rows.append({'message':  message, 'text': message['messageBody'], 'type': 1})\n",
    "                 \n",
    "\n",
    "for message in nonQuestions:\n",
    "    rows.append({'message':  message, 'text': message['messageBody'], 'type': 0})\n",
    "    \n",
    "\n",
    "data_frame = pd.DataFrame(rows)\n",
    "data = data.append(data_frame)\n",
    "\n",
    "data = data.take(np.random.permutation(len(data)))\n",
    "data.reset_index(drop = True, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = dic2\n",
    "values = [] # Values are the values and their percentage decrease\n",
    "valuePairs = []\n",
    "for key in dic:\n",
    "    case = dic[key]\n",
    "    for i in range(1, len(case) -1):\n",
    "        if (case[i] not in [None, 0] and case[i+1]!= None and case[i] > case[i+1]):\n",
    "            if case[i] < 5000:\n",
    "                values += [(case[i], (case[i]-case[i+1])/case[i])]\n",
    "            \n",
    "                valuePairs += [(case[i], case[i+1])]\n",
    "\n",
    "val = [] #value\n",
    "pcDec = [] #percentage change\n",
    "value1 = []\n",
    "value2 = []\n",
    "\n",
    "for v in values:\n",
    "    val += [[v[0]]]\n",
    "    pcDec += [[v[1]]]\n",
    "\n",
    "for v in valuePairs:\n",
    "    value1 += [[v[0]]]\n",
    "    value2 += [[v[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'val1': [], 'val2': []})\n",
    "rows = []\n",
    "for values in valuePairs:\n",
    "    rows.append({'val1':  values[0], 'val2':  values[1]})\n",
    " \n",
    "    \n",
    "\n",
    "data_frame = pd.DataFrame(rows)\n",
    "data = data.append(data_frame)\n",
    "\n",
    "data = data.take(np.random.permutation(len(data)))\n",
    "data.reset_index(drop = True, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 32.7892295])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([(\"selector\", DataFrameSelector([\"val1\"]))])\n",
    "\n",
    "linreg = LinearRegression()\n",
    "y = data[\"val2\"].values\n",
    "X = pipeline.transform(data)\n",
    "linreg.fit(X, y)\n",
    "linreg.predict(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[  8.00000000e+00   2.30000000e+01   2.37600000e+03   1.09500000e+02\n   4.00000000e+00   4.90000000e+01   4.08000000e+02   3.60000000e+01\n   1.20000000e+01   2.49000000e+02   1.02600000e+03   2.00000000e+00\n   2.00000000e+00   1.20000000e+01   2.51000000e+02   3.10000000e+01\n   1.80000000e+01   7.00000000e+00   2.80000000e+01   1.30000000e+01\n   7.00000000e+00   1.70000000e+01   1.45000000e+02   7.20000000e+01\n   1.10000000e+01   3.66400000e+03   2.13000000e+02   5.00000000e+00\n   4.80000000e+01   3.00000000e+01   3.98000000e+03   3.41400000e+03\n   6.52000000e+02   5.07000000e+02   2.60000000e+01   1.82000000e+02\n   4.00000000e+00   4.36900000e+03   1.80000000e+01   1.60000000e+01\n   8.00000000e+00   4.00000000e+00   4.00000000e+00   2.00000000e+00\n   8.85000000e+02   2.67900000e+03   4.00000000e+00   1.66500000e+02\n   1.15900000e+03   2.23000000e+02   1.40000000e+01   6.00000000e+00\n   1.45000000e+02   2.72950000e+03   1.72900000e+03   5.00000000e+00\n   2.70000000e+01   3.00000000e+01   6.00000000e+00   1.10000000e+01\n   3.00000000e+00   4.04500000e+02   3.00000000e+00   2.10600000e+03\n   3.00000000e+00   3.40000000e+01   7.13000000e+02   1.10000000e+01\n   1.25000000e+03   7.90000000e+02   3.25000000e+02   1.33600000e+03\n   3.40000000e+01   1.52000000e+02   6.30000000e+01   7.50000000e+01\n   4.69000000e+02   3.00000000e+00   2.90000000e+01   5.50000000e+01\n   6.44000000e+02   3.00000000e+01   7.40000000e+01   8.00000000e+00\n   1.64400000e+03   5.00000000e+00   1.90000000e+01   5.30000000e+01\n   5.79000000e+02   3.13000000e+02   1.10000000e+01   2.40000000e+01\n   1.96000000e+02   8.20000000e+01   2.09000000e+02   4.61200000e+03\n   8.80000000e+01   8.80000000e+01   5.00000000e+00   3.00000000e+00\n   4.50000000e+01   5.90000000e+01   3.00000000e+00   1.97000000e+02\n   6.50000000e+01   3.57000000e+02   4.00000000e+00   3.80000000e+01\n   7.22000000e+02   2.00000000e+00   1.50000000e+01   5.00000000e+00\n   2.40000000e+03   5.00000000e+00   8.21000000e+02   5.00000000e+00\n   2.00000000e+00   1.12000000e+02   3.00000000e+00   1.80000000e+01\n   7.00000000e+00   4.00000000e+00   4.50000000e+01   2.79600000e+03\n   2.90000000e+02   2.64000000e+02   3.01000000e+03   1.10400000e+03\n   1.67200000e+03   7.28000000e+02   8.00000000e+00   3.56800000e+03\n   6.76000000e+02   4.30000000e+01   6.20000000e+01   3.80000000e+01\n   9.00000000e+00   1.70000000e+01   1.42500000e+03   8.00000000e+00\n   2.40000000e+01   2.52000000e+02   8.00000000e+00   8.00000000e+00\n   5.60000000e+01   4.90000000e+01   1.92000000e+02   2.55500000e+03\n   2.95000000e+02   3.00000000e+00   2.48000000e+02   2.00000000e+00\n   2.00000000e+00   2.01000000e+02   3.94000000e+02   1.13000000e+02\n   1.78300000e+03   1.10000000e+02   1.30000000e+01   1.53000000e+02\n   3.00000000e+00   3.90000000e+01   1.20000000e+01   3.00000000e+00\n   4.24300000e+03   2.27000000e+02   1.54000000e+02   5.00000000e+01\n   6.14000000e+02   4.73000000e+02   3.88000000e+02   1.60000000e+02\n   2.00000000e+00   4.10000000e+01   1.63000000e+02   2.79200000e+03\n   3.32700000e+03   4.50000000e+02   3.70900000e+03   6.00000000e+00\n   3.66000000e+02   5.00000000e+00   8.70000000e+01   5.00000000e+00\n   4.40000000e+01   1.70000000e+01   3.60000000e+01   3.00000000e+00\n   1.00000000e+01   5.00000000e+00   1.94300000e+03   9.69000000e+02\n   3.30000000e+01   1.52500000e+03   1.97900000e+03   5.04000000e+02\n   3.00000000e+00   5.80000000e+01   2.00000000e+01   2.75000000e+01\n   8.00000000e+00   6.00000000e+00   1.07000000e+02   6.20000000e+02\n   5.20000000e+01   9.90000000e+01   5.00000000e+00   4.04100000e+03\n   1.40000000e+01   5.57500000e+02   6.30000000e+01   6.00000000e+00\n   8.00000000e+00   4.00000000e+00   6.12000000e+02   2.50000000e+01\n   9.00000000e+00   3.00000000e+00   2.60000000e+01   3.25000000e+01\n   3.00000000e+00   1.20000000e+01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-14949e2bdf1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     (\"estimator\", LogisticRegression())])\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mk_fold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\brian\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\brian\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[1;32m-> 1216\u001b[1;33m                          order=\"C\")\n\u001b[0m\u001b[0;32m   1217\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\brian\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    540\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    541\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    543\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mc:\\users\\brian\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    408\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    411\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m             \u001b[1;31m# To ensure that array flags are maintained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[  8.00000000e+00   2.30000000e+01   2.37600000e+03   1.09500000e+02\n   4.00000000e+00   4.90000000e+01   4.08000000e+02   3.60000000e+01\n   1.20000000e+01   2.49000000e+02   1.02600000e+03   2.00000000e+00\n   2.00000000e+00   1.20000000e+01   2.51000000e+02   3.10000000e+01\n   1.80000000e+01   7.00000000e+00   2.80000000e+01   1.30000000e+01\n   7.00000000e+00   1.70000000e+01   1.45000000e+02   7.20000000e+01\n   1.10000000e+01   3.66400000e+03   2.13000000e+02   5.00000000e+00\n   4.80000000e+01   3.00000000e+01   3.98000000e+03   3.41400000e+03\n   6.52000000e+02   5.07000000e+02   2.60000000e+01   1.82000000e+02\n   4.00000000e+00   4.36900000e+03   1.80000000e+01   1.60000000e+01\n   8.00000000e+00   4.00000000e+00   4.00000000e+00   2.00000000e+00\n   8.85000000e+02   2.67900000e+03   4.00000000e+00   1.66500000e+02\n   1.15900000e+03   2.23000000e+02   1.40000000e+01   6.00000000e+00\n   1.45000000e+02   2.72950000e+03   1.72900000e+03   5.00000000e+00\n   2.70000000e+01   3.00000000e+01   6.00000000e+00   1.10000000e+01\n   3.00000000e+00   4.04500000e+02   3.00000000e+00   2.10600000e+03\n   3.00000000e+00   3.40000000e+01   7.13000000e+02   1.10000000e+01\n   1.25000000e+03   7.90000000e+02   3.25000000e+02   1.33600000e+03\n   3.40000000e+01   1.52000000e+02   6.30000000e+01   7.50000000e+01\n   4.69000000e+02   3.00000000e+00   2.90000000e+01   5.50000000e+01\n   6.44000000e+02   3.00000000e+01   7.40000000e+01   8.00000000e+00\n   1.64400000e+03   5.00000000e+00   1.90000000e+01   5.30000000e+01\n   5.79000000e+02   3.13000000e+02   1.10000000e+01   2.40000000e+01\n   1.96000000e+02   8.20000000e+01   2.09000000e+02   4.61200000e+03\n   8.80000000e+01   8.80000000e+01   5.00000000e+00   3.00000000e+00\n   4.50000000e+01   5.90000000e+01   3.00000000e+00   1.97000000e+02\n   6.50000000e+01   3.57000000e+02   4.00000000e+00   3.80000000e+01\n   7.22000000e+02   2.00000000e+00   1.50000000e+01   5.00000000e+00\n   2.40000000e+03   5.00000000e+00   8.21000000e+02   5.00000000e+00\n   2.00000000e+00   1.12000000e+02   3.00000000e+00   1.80000000e+01\n   7.00000000e+00   4.00000000e+00   4.50000000e+01   2.79600000e+03\n   2.90000000e+02   2.64000000e+02   3.01000000e+03   1.10400000e+03\n   1.67200000e+03   7.28000000e+02   8.00000000e+00   3.56800000e+03\n   6.76000000e+02   4.30000000e+01   6.20000000e+01   3.80000000e+01\n   9.00000000e+00   1.70000000e+01   1.42500000e+03   8.00000000e+00\n   2.40000000e+01   2.52000000e+02   8.00000000e+00   8.00000000e+00\n   5.60000000e+01   4.90000000e+01   1.92000000e+02   2.55500000e+03\n   2.95000000e+02   3.00000000e+00   2.48000000e+02   2.00000000e+00\n   2.00000000e+00   2.01000000e+02   3.94000000e+02   1.13000000e+02\n   1.78300000e+03   1.10000000e+02   1.30000000e+01   1.53000000e+02\n   3.00000000e+00   3.90000000e+01   1.20000000e+01   3.00000000e+00\n   4.24300000e+03   2.27000000e+02   1.54000000e+02   5.00000000e+01\n   6.14000000e+02   4.73000000e+02   3.88000000e+02   1.60000000e+02\n   2.00000000e+00   4.10000000e+01   1.63000000e+02   2.79200000e+03\n   3.32700000e+03   4.50000000e+02   3.70900000e+03   6.00000000e+00\n   3.66000000e+02   5.00000000e+00   8.70000000e+01   5.00000000e+00\n   4.40000000e+01   1.70000000e+01   3.60000000e+01   3.00000000e+00\n   1.00000000e+01   5.00000000e+00   1.94300000e+03   9.69000000e+02\n   3.30000000e+01   1.52500000e+03   1.97900000e+03   5.04000000e+02\n   3.00000000e+00   5.80000000e+01   2.00000000e+01   2.75000000e+01\n   8.00000000e+00   6.00000000e+00   1.07000000e+02   6.20000000e+02\n   5.20000000e+01   9.90000000e+01   5.00000000e+00   4.04100000e+03\n   1.40000000e+01   5.57500000e+02   6.30000000e+01   6.00000000e+00\n   8.00000000e+00   4.00000000e+00   6.12000000e+02   2.50000000e+01\n   9.00000000e+00   3.00000000e+00   2.60000000e+01   3.25000000e+01\n   3.00000000e+00   1.20000000e+01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"estimator\", LogisticRegression())])\n",
    "\n",
    "pipeline.fit(data['val1'].values, data['val2'].values)\n",
    "\n",
    "k_fold = KFold(n=len(data), n_folds=6)\n",
    "scores = []\n",
    "confusion = numpy.array([[0, 0], [0, 0]])\n",
    "\n",
    "\n",
    "for train, test in k_fold:\n",
    "    train_text = data.iloc[train]['header'].values\n",
    "    train_y = data.iloc[train]['type'].values\n",
    "\n",
    "    test_text = data.iloc[test]['header'].values\n",
    "    test_y = data.iloc[test]['type'].values\n",
    "\n",
    "    pipeline.fit(train_text, train_y)\n",
    "    predictions = pipeline.predict(test_text)\n",
    "\n",
    "    confusion += confusion_matrix(test_y, predictions)\n",
    "    score = f1_score(test_y, predictions, pos_label=1)\n",
    "    scores.append(score)\n",
    "\n",
    "print(\"Scores: \", scores)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val1</th>\n",
       "      <th>val2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2376.0</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109.5</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>49.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>408.0</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>249.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1026.0</td>\n",
       "      <td>313.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>251.0</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>31.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>28.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>145.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>72.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3664.0</td>\n",
       "      <td>1250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>213.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>48.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>33.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1525.0</td>\n",
       "      <td>713.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1979.0</td>\n",
       "      <td>504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>504.0</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>58.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>27.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>107.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>620.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>52.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>99.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>4041.0</td>\n",
       "      <td>1644.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>557.5</td>\n",
       "      <td>325.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>63.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>612.0</td>\n",
       "      <td>366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>26.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>32.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       val1    val2\n",
       "0       8.0     4.0\n",
       "1      23.0     4.0\n",
       "2    2376.0   112.0\n",
       "3     109.5    23.0\n",
       "4       4.0     3.0\n",
       "5      49.0    10.0\n",
       "6     408.0   227.0\n",
       "7      36.0    24.0\n",
       "8      12.0     7.0\n",
       "9     249.0    30.0\n",
       "10   1026.0   313.0\n",
       "11      2.0     0.0\n",
       "12      2.0     0.0\n",
       "13     12.0     5.0\n",
       "14    251.0   152.0\n",
       "15     31.0    17.0\n",
       "16     18.0     6.0\n",
       "17      7.0     5.0\n",
       "18     28.0    11.0\n",
       "19     13.0     5.0\n",
       "20      7.0     4.0\n",
       "21     17.0    11.0\n",
       "22    145.0    43.0\n",
       "23     72.0    26.0\n",
       "24     11.0     6.0\n",
       "25   3664.0  1250.0\n",
       "26    213.0   160.0\n",
       "27      5.0     3.0\n",
       "28     48.0    36.0\n",
       "29     30.0     3.0\n",
       "..      ...     ...\n",
       "192    33.0    17.0\n",
       "193  1525.0   713.0\n",
       "194  1979.0   504.0\n",
       "195   504.0   182.0\n",
       "196     3.0     0.0\n",
       "197    58.0    19.0\n",
       "198    20.0     2.0\n",
       "199    27.5     2.0\n",
       "200     8.0     4.0\n",
       "201     6.0     2.0\n",
       "202   107.0    75.0\n",
       "203   620.0     6.0\n",
       "204    52.0    12.0\n",
       "205    99.0    55.0\n",
       "206     5.0     2.0\n",
       "207  4041.0  1644.0\n",
       "208    14.0     4.0\n",
       "209   557.5   325.0\n",
       "210    63.0    31.0\n",
       "211     6.0     3.0\n",
       "212     8.0     5.0\n",
       "213     4.0     3.0\n",
       "214   612.0   366.0\n",
       "215    25.0     5.0\n",
       "216     9.0     5.0\n",
       "217     3.0     0.0\n",
       "218    26.0    13.0\n",
       "219    32.5     3.0\n",
       "220     3.0     0.0\n",
       "221    12.0     4.0\n",
       "\n",
       "[222 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
